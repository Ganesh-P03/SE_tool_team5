import tensorflow as tfimport numpy as npimport pandas as pdimport requestsdef get_data():    url = "https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv"    response = requests.get(url)    data = response.content.decode()    return pd.read_csv(data)def preprocess_data(data):    data = data.dropna()    data = data.drop("ocean_proximity", axis=1)    data = data.drop("total_bedrooms", axis=1)    data = data.drop("total_rooms", axis=1)    data = data.drop("households", axis=1)    data = data.drop("longitude", axis=1)    data = data.drop("latitude", axis=1)    data = data.drop("population", axis=1)    return datadef get_train_test_data(data):    train_data = data.sample(frac=0.8, random_state=0)    test_data = data.drop(train_data.index)    return train_data, test_datadef get_train_test_labels(train_data, test_data):    train_labels = train_data.pop("median_house_value")    test_labels = test_data.pop("median_house_value")    return train_labels, test_labelsdef get_normalization_layer(data):    normalizer = tf.keras.layers.experimental.preprocessing.Normalization()    normalizer.adapt(np.array(data))    return normalizer